<!DOCTYPE HTML PUBLIC "-//W3C//DTD HTML 4.01 Transitional//EN">
<html>
  <head>
  <meta name=viewport content=“width=800”>
  <meta name="generator" content="HTML Tidy for Linux/x86 (vers 11 February 2007), see www.w3.org">	  
  <link rel="stylesheet" type="text/css" href="stylesheet.css">	  
  <link rel="icon" type="image/png" href="resource/Chethan_Parameshwara.jpg">
  <script type="text/javascript" src="resource/hidebib.js"></script>
  <title>Chethan M Parameshwara</title>
  <meta http-equiv="Content-Type" content="text/html; charset=us-ascii">
  <link href='http://fonts.googleapis.com/css?family=Lato:400,700,400italic,700italic' rel='stylesheet' type='text/css'>
  </head>
  <body>
  <table width="800" border="0" align="center" cellspacing="0" cellpadding="0">
    <tr>
    <td>
      <table width="100%" align="center" border="0" cellspacing="0" cellpadding="20">
      <tr>
        <td width="67%" valign="middle">
        <p align="center">
          <name>Chethan M Parameshwara</name>
        </p>
        <p> </p>
	<p>I am a Ph.D. candidate in the <a href="https://nacs.umd.edu/" target="_blank">Neuroscience and Cognitive Science (NACS)</a> program at the <a href="https://umd.edu/" target="_blank">University of Maryland, College Park (UMD)</a>,
		working with my advisors <a href="http://www.cfar.umd.edu/~yiannis/" target="_blank">Prof. Yiannis Aloimonos</a> and <a href=" http://www.cfar.umd.edu/~fer/" target="_blank"> Dr. Cornelia Fermüller</a> in 
		<a href="http://prg.cs.umd.edu/">Perception & Robotics Group</a>.
		</p>
		
		<p> I specialize in developing computer vision and machine learning algorithms for resource-constrained robotic systems. My research work is generously supported by <a href="https://nacs.umd.edu/students/awards-and-assistantships" target="_blank">William Hodos Dissertation Assistantship</a>, <a href="https://gradschool.umd.edu/sites/gradschool.umd.edu/files/uploads/Awards/Recipients/summerresfellows_summer_2020.pdf" target="_blank"> Graduate School Summer Research Fellowship</a>, 
			<a href="https://www.nsf.gov/index.jsp" target="_blank">NSF</a>, <a href="https://www.northropgrumman.com/" target="_blank">Northrop Grumman</a>, and <a href="https://www.samsung.com/" target="_blank">Samsung</a>.</p>
	<p>Prior to joining the Ph.D. program, I received Master's degree in Robotics Engineering from <a href="https://eng.umd.edu/" target="_blank">A. James Clark School of Engineering</a>  at UMD and Bachelor's degree in Electronics and Communication Engineering from <a href="http://vtu.ac.in/" target="_blank">Visvesvaraya Technological University, India</a>.</p>

<p>Since then, I have had the pleasure to work at:</p>
<ul>
<li>[2021] <a href="https://www.sri.com/" target="_blank">SRI International</a> as a research intern with <a href="https://www.linkedin.com/in/david-zhang-99217920/" target="_blank">Dr. David Zhang</a>
</li>
<li>[2019] <a href="https://www.neurala.com/" target="_blank">Neurala</a> as a research intern with <a href="https://www.linkedin.com/in/anatoli-gorchet-427a0720/" target="_blank">Dr. Anatoli Gorchet</a>
</li>	
<li>[2014] <a href="http://www.bosch-india-software.com/en/index.html" target="_blank">Bosch</a> as a software engineer
</li>
<li>[2013] <a href="http://www.iisc.ac.in/" target="_blank">Indian Institute of Science</a> as a research intern with <a href="https://ece.iisc.ac.in/~vinod/" target="_blank">Prof. Vinod Sharma</a>
</li>
</ul>

        <p align=center>
	  <!-- a href="https://analogicalnexus.github.io/resource/Chethan_CV.pdf">CV</a-->
          <a href="mailto:cmparam9@terpmail.umd.edu">Email</a> &nbsp/&nbsp
          <a href="https://github.com/analogicalnexus">GitHub</a> &nbsp/&nbsp
          <!--a href="">Thesis</a-->
          <a href="https://scholar.google.com/citations?user=tStSA4AAAAAJ&hl=en">Google Scholar</a> &nbsp/&nbsp 
          <a href="http://www.linkedin.com/in/cmparam/"> LinkedIn </a>
	  <!--a href="https://analogicalnexus.github.io/blog/">Blog</a-->
        </p>
        </td>
              <td width="66%">
                <img class="img-circle" height="280px" src="resource/Chethan_Parameshwara.jpg">
              </td>
      </tr>
      </table>
<!-- News -->
      <table width="100%" align="center" border="0" cellspacing="0" cellpadding="20">
        <tbody><tr><td>
            <heading>Highlights</heading>
            <ul>
		<li>[Jun 2021] <a href="https://arxiv.org/abs/2105.06562" target="_blank">SpikeMS</a> paper got accepted to IROS 2021</li>
		<li>[May 2021] <a href="https://prg.cs.umd.edu/EVPropNet" target="_blank">EVPropNet</a> paper got accepted to RSS 2021</li>
		<li>[May 2021] Delighted to receive <a href="https://nacs.umd.edu/students/awards-and-assistantships" target="_blank">William Hodos Dissertation Assistantship</a> </li>
		<li>[Apr 2021] <a href="http://prg.cs.umd.edu/0-MMS" target="_blank">0-MMS</a> paper got accepted to ICRA 2021</li>
		<li>[Jun 2020] Recipient of <a href="https://gradschool.umd.edu/sites/gradschool.umd.edu/files/uploads/Awards/Recipients/summerresfellows_summer_2020.pdf" target="_blank"> Graduate School Summer Research Fellowship </a> </li> 
		<li>[May 2020] <a href="http://prg.cs.umd.edu/EVDodgeNet" target="_blank">EVDodgeNet</a> paper got accepted to ICRA 2020</li>
		<li>[Jul 2018] <a href="http://prg.cs.umd.edu/BetterFlow.html" target="_blank">Event-based Moving Object Detection and Tracking</a> paper got accepted to IROS 2018 </li>
	        <li>[Aug 2017] Starting PhD in Neuroscience and Cognitive Science</li>
            </ul>
        </td></tr>      
	    </table>
<!-- Research -->
      <table width="100%" align="center" border="0" cellspacing="0" cellpadding="20">
      <tr>
        <td width="100%" valign="middle">
          <heading>Research</heading>
          <p> My research interest lies at the intersection of computer vision, machine learning, and robotics. The current focus is to develop novel algorithms for 3D perception (motion segmentation, visual odometry, optical flow estimation, SLAM, SfM) and few/zero-shot object classification, detection, and tracking. The proposed approaches aim explicitly to minimize power, memory, and latency and are designed for difficult scenarios such as high-speed motion, challenging lighting, and dynamic scenes.
           </p>
        </td>
      </tr>
      </table>

	  
	 <table style="width:100%;border:0px;border-spacing:0px;border-collapse:separate;margin-right:auto;margin-left:auto;"><tbody>
		 
	   <!--tr>
            <td style="padding:20px;width:25%;vertical-align:middle">
              <img src="resource/momswithevents.png" alt="b3do" width="160" style="border-style: none">
            </td-->
	<tr onmouseout="spikems_stop()" onmouseover="spikems_start()">
            <td style="padding:20px;width:25%;vertical-align:middle">
              <div class="one">
                <div class="two" id='spikems_image'>
                  <img src='resource/spikems_output.png' width="160" height="160" style="border-style: none">
                </div>
                <img src='resource/spikems_input.png' width="160" height="160" style="border-style: none">
              </div>
              <script type="text/javascript">
                function spikems_start() {
                  document.getElementById('spikems_image').style.opacity = "1";
                }

                function spikems_stop() {
                  document.getElementById('spikems_image').style.opacity = "0";
                }
                spikems_stop()
              </script>
            </td>
            <td style="padding:20px;width:75%;vertical-align:middle">
              <a href="https://arxiv.org/abs/2105.06562">
                <papertitle>SpikeMS: Deep Spiking Neural Network for Motion Segmentation</papertitle>
              </a>
              <br>
              <strong>Chethan M. Parameshwara*</strong>,
	      <a href="https://www.linkedin.com/in/simin-li-88088b/">Simin Li*</a>,
	      <a href="http://users.umiacs.umd.edu/~fer/">Cornelia Fermüller</a>,
              <a href="https://nitinjsanket.github.io/">Nitin J. Sanket</a>,
	      <a href="https://www.linkedin.com/in/matthew-evanusa-8772109b/">Matthew S. Evanusa</a>,
	      <a href="http://users.umiacs.umd.edu/~yiannis/">Yiannis Aloimonos</a> (* equal contribution)		
              <br>
        <em><a href=" https://www.iros2021.org/">IROS, 2021</a></em> 
              <br>
              project page /
              code /
              <a href="https://arxiv.org/abs/2105.06562">arXiv</a> /
              video
              <p></p>
              <p> We propose a spiking neural network for the motion segmentation problem using an asynchronous event camera.</p>
            </td>
          </tr>  
		 
	<!--tr onmouseout="evpropnet_stop()" onmouseover="evpropnet_start()">
            <td style="padding:20px;width:25%;vertical-align:middle">
              <div class="one">
                <div class="two" id='evpropnet_image'>
                  <img src='resource/evpropnet_after.png' width="160" height="160" style="border-style: none">
                </div>
                <img src='resource/evpropnet_before.png' width="160" height="160" style="border-style: none">
              </div>
              <script type="text/javascript">
                function evpropnet_start() {
                  document.getElementById('evpropnet_image').style.opacity = "1";
                }

                function evpropnet_stop() {
                  document.getElementById('evpropnet_image').style.opacity = "0";
                }
                momswithevents_stop()
              </script>
            </td-->
			 
	   <tr onmouseout="evpropnet_stop()" onmouseover="evpropnet_start()">
            <td style="padding:20px;width:25%;vertical-align:middle">
              <div class="one">
                <div class="two" id='evpropnet_image'><img src='resource/evpropnet.gif'></div>
                <img src='resource/evpropnet.png'>
              </div>
              <script type="text/javascript">
                function evpropnet_start() {
                  document.getElementById('evpropnet_image').style.opacity = "1";
                }

                function evpropnet_stop() {
                  document.getElementById('evpropnet_image').style.opacity = "0";
                }
                evpropnet_stop()
              </script>
            </td>
            <td style="padding:20px;width:75%;vertical-align:middle">
              <a href="https://arxiv.org/abs/2106.15045">
                <papertitle>EVPropNet: Detecting Drones By Finding Propellers For Mid-Air Landing And Following</papertitle>
              </a>
              <br>
              <a href="https://nitinjsanket.github.io/">Nitin J. Sanket</a>,
              <a href="https://chahatdeep.github.io/">Chahat Deep Singh</a>,
	      <strong>Chethan M. Parameshwara</strong>,
              <a href="http://users.umiacs.umd.edu/~fer/">Cornelia Fermüller</a>,
	      <a href="http://www.bene-guido.eu/wordpress/"> Guido de Croon</a>,	   
	      <a href="http://users.umiacs.umd.edu/~yiannis/">Yiannis Aloimonos</a>
              <br>
        	<em><a href="https://roboticsconference.org/">RSS, 2021</a></em>  
              <br>
              <a href="https://prg.cs.umd.edu/EVPropNet">project page</a> /
              <a href="https://github.com/prgumd/EVPropNet">code</a> /
              <a href="https://arxiv.org/abs/2106.15045">arXiv</a> /
              <a href="https://www.youtube.com/watch?v=WpRB_3dyXTs">video</a>
              <p></p>
              <p> We present a deep learning-based solution for detecting propellers (to detect drones) for mid-air landing and following.</p>
            </td>
          </tr>  
		 
		 
			 
	 <!--tr onmouseout="momswithevents_stop()" onmouseover="momswithevents_start()">
            <td style="padding:20px;width:25%;vertical-align:middle">
              <div class="one">
                <div class="two" id='momswithevents_image'>
                  <img src='resource/momswithevents_after.png' width="160" height="160" style="border-style: none">
                </div>
                <img src='resource/momswithevents_before.png' width="160" height="160" style="border-style: none">
              </div>
              <script type="text/javascript">
                function momswithevents_start() {
                  document.getElementById('momswithevents_image').style.opacity = "1";
                }

                function momswithevents_stop() {
                  document.getElementById('momswithevents_image').style.opacity = "0";
                }
                momswithevents_stop()
              </script>
            </td-->
		 
	  <tr onmouseout="mms_stop()" onmouseover="mms_start()">
            <td style="padding:20px;width:25%;vertical-align:middle">
              <div class="one">
                <div class="two" id='mms_image'><img src='resource/0-mms.gif'></div>
                <img src='resource/0-mms.png'>
              </div>
              <script type="text/javascript">
                function mms_start() {
                  document.getElementById('mms_image').style.opacity = "1";
                }

                function mms_stop() {
                  document.getElementById('mms_image').style.opacity = "0";
                }
                mms_stop()
              </script>
            </td>
            <td style="padding:20px;width:75%;vertical-align:middle">
              <a href="https://arxiv.org/abs/2006.06158">
                <papertitle>0-MMS: Zero-Shot Multi-Motion Segmentation With A Monocular Event Camera</papertitle>
              </a>
              <br>
              <strong>Chethan M. Parameshwara</strong>,
              <a href="https://nitinjsanket.github.io/">Nitin J. Sanket</a>,
              <a href="https://chahatdeep.github.io/">Chahat Deep Singh</a>,
              <a href="http://users.umiacs.umd.edu/~fer/">Cornelia Fermüller</a>,
	      <a href="http://users.umiacs.umd.edu/~yiannis/">Yiannis Aloimonos</a>
              <br>
        	<em><a href="https://www.ieee-icra.org/">ICRA, 2021</a></em>  
              <br>
              <a href="http://prg.cs.umd.edu/0-MMS">project page</a> /
              <a href="https://github.com/prgumd/0-MMS">code</a> /
              <a href="https://arxiv.org/abs/2006.06158">arXiv</a> /
              <a href="https://www.youtube.com/watch?v=KdpZkxjp02E">video</a>
              <p></p>
              <p> We propose a hybrid solution to multi-object motion segmentation using a combination of model-based and deep learning approaches with minimal prior knowledge.</p>
            </td>
          </tr>  
		 
		 

		 

	   <!--tr onmouseout="evdodgenet_stop()" onmouseover="evdodgenet_start()">
            <td style="padding:20px;width:25%;vertical-align:middle">
              <div class="one">
                <div class="two" id='evdodgenet_image'>
                  <img src='resource/evdodgenet_after.png' width="160" height="160" style="border-style: none">
                </div>
                <img src='resource/evdodgenet_before.png' width="160" height="160" style="border-style: none">
              </div>
              <script type="text/javascript">
                function evdodgenet_start() {
                  document.getElementById('evdodgenet_image').style.opacity = "1";
                }

                function evdodgenet_stop() {
                  document.getElementById('evdodgenet_image').style.opacity = "0";
                }
                evdodgenet_stop()
              </script>
            </td-->
		   
		   
	   <tr onmouseout="evdodge_stop()" onmouseover="evdodge_start()">
            <td style="padding:20px;width:25%;vertical-align:middle">
              <div class="one">
                <div class="two" id='evdodge_image'><img src='resource/evdodge.gif'></div>
                <img src='resource/evdodge.png'>
              </div>
              <script type="text/javascript">
                function evdodge_start() {
                  document.getElementById('evdodge_image').style.opacity = "1";
                }

                function evdodge_stop() {
                  document.getElementById('evdodge_image').style.opacity = "0";
                }
                evdodge_stop()
              </script>
            </td>
            <td style="padding:20px;width:75%;vertical-align:middle">
              <a href="http://prg.cs.umd.edu/EVDodgeNet">
                <papertitle>EVDodgeNet: Deep Dynamic Obstacle Dodging with event cameras</papertitle>
              </a>
              <br>
              <strong>Chethan M. Parameshwara*</strong>,
              <a href="https://nitinjsanket.github.io/">Nitin J. Sanket*</a>,
              <a href="https://chahatdeep.github.io/">Chahat Deep Singh</a>,
              <a href="">Ashwin V. Kuruttukulam</a>,
              <a href="http://users.umiacs.umd.edu/~fer/">Cornelia Fermüller</a>,
	      <a href="http://rpg.ifi.uzh.ch/people_scaramuzza.html">Davide Scaramuzza</a>,
	      <a href="http://users.umiacs.umd.edu/~yiannis/">Yiannis Aloimonos</a>
	      (* equal contribution)
              <br>
	      <em><a href="https://www.ieee-ras.org/students/events/event/1144-icra-2020-ieee-international-conference-on-robotics-and-automation-icra">ICRA, 2020</a></em>
  
              <br>
              <a href="http://prg.cs.umd.edu/EVDodgeNet">project page</a>
        /
              <a href="https://github.com/prgumd/EVDodgeNet">code</a>
        /
              <a href="https://arxiv.org/abs/1906.02919">arXiv</a>
        /
              <a href="https://www.youtube.com/watch?v=NSwK1ZEsTOo">video</a>
              <p></p>
              <p> We present the first deep learning based solution for dodging multiple dynamic obstacles on a quadrotor with a single event camera and onboard computation.</p>
            </td>
          </tr>  
	
	    
	 <table style="width:100%;border:0px;border-spacing:0px;border-collapse:separate;margin-right:auto;margin-left:auto;"><tbody>
		 
	   <!--tr>
            <td style="padding:20px;width:25%;vertical-align:middle">
              <img src="resource/betterflow.PNG" alt="b3do" width="160" style="border-style: none">
            </td-->
	 <tr onmouseout="betterflow_stop()" onmouseover="betterflow_start()">
            <td style="padding:20px;width:25%;vertical-align:middle">
              <div class="one">
                <div class="two" id='betterflow_image'>
                  <img src='resource/betterflow_after.png' width="160" height="160" style="border-style: none">
                </div>
                <img src='resource/betterflow_before.png' width="160" height="160" style="border-style: none">
              </div>
              <script type="text/javascript">
                function betterflow_start() {
                  document.getElementById('betterflow_image').style.opacity = "1";
                }

                function betterflow_stop() {
                  document.getElementById('betterflow_image').style.opacity = "0";
                }
                betterflow_stop()
              </script>
            </td>
            <td style="padding:20px;width:75%;vertical-align:middle">
              <a href="http://prg.cs.umd.edu/BetterFlow">
                <papertitle>Event-based Moving Object Detection and Tracking</papertitle>
              </a>
              <br>
	      <a href="https://ncos.github.io/amitrokh/">Anton Mitrokhin</a>,    
	      <a href="http://users.umiacs.umd.edu/~fer/">Cornelia Fermüller</a>,
              <strong>Chethan M. Parameshwara</strong>,
	      <a href="http://users.umiacs.umd.edu/~yiannis/">Yiannis Aloimonos</a>
              <br>
        <em><a href=" https://www.iros2018.org/">IROS, 2018</a></em> 
              <br>
              <a href="http://prg.cs.umd.edu/BetterFlow">project page</a>
        /
              <a href="https://github.com/better-flow/better-flow">code</a>
        /
              <a href="https://arxiv.org/pdf/1803.04523.pdf">arXiv</a>
        /
              <a href="https://www.youtube.com/watch?v=UCAJi0ZFaZ8">video</a>
              <p></p>
              <p> We present a novel motion compensation approach for moving object tracking with an asynchronous event camera.</p>
            </td>
          </tr> 
         </tbody></table>


<!--Teaching-->
	  <table width="100%" align="center" border="0" cellspacing="0" cellpadding="20"><tbody>
          <tr>
            <td>
              <heading>Teaching</heading>
            </td>
          </tr>
        </tbody></table>
	<table width="100%" align="center" border="0" cellpadding="20"><tbody>
          <tr>
            <td style="padding:20px;width:25%;vertical-align:middle">
              <img src="resource/intrinsic-pinhole-camera.png" alt="panoroma" width="160" height="160">
            </td>
            <td width="75%" valign="center">
              Teaching Assistant, <a href="http://prg.cs.umd.edu/cmsc733">CMSC733 : Geometric Computer Vision</a>
              <br>
              <br>
	      Teaching Assistant, <a href="http://prg.cs.umd.edu/cmsc426">CMSC426 : Computer Vision</a>
              <br>
	      <br>
              Teaching Assistant, <a href="https://umd.instructure.com/courses/1257184">CMSC434 : Human Computer Interaction</a>
            </td>
          </tr>
        </tbody></table>
	   	    
<!--Service -->
	  <table width="100%" align="center" border="0" cellspacing="0" cellpadding="20"><tbody>
          <tr>
            <td>
              <heading>Volunteering</heading>
            </td>
          </tr>
        </tbody></table>
        <table width="100%" align="center" border="0" cellpadding="20"><tbody>
          <tr>
            <td style="padding:20px;width:25%;vertical-align:middle"><img src="resource/umd_logo.png"  alt="gsglogo" width="160" height="160">
	    </td>
            <td width="75%" valign="middle">
	      Reviewer: <a href="https://www.ieee-ras.org/publications/ra-l">RAL'20</a>, <a href="https://www.icra2020.org/">ICRA'20</a>, <a href="https://www.ieee-ras.org/publications/ra-l">RAL'21</a>, <a href="https://www.ieee-icra.org/">ICRA'21</a>, <a href="https://www.iros2021.org/">IROS'21</a>, <a href="https://ieee-sensors.org/sensors-journal/">IEEE Sensor Journal</a>
              <br>
              <br>
              NACS Representative, <a href="https://www.gsgumd.org/">UMD Graduate Student Government (2020-2021)</a>
              <br>
              <br>
              Co-Chair, <a href="https://nacs.umd.edu/about-us/committees">NACS Grant Review Committee (2019-Present)</a>
	      <br>
              <br>
              Staff Member, <a href="https://sites.google.com/view/telluride2018/home">Neuromorphic Cognition Engineering Workshop (July 2018)</a>	        
            </td>
          </tr>
	  </tbody></table>


<!-- Footer -->
        <table width="100%" align="center" border="0" cellspacing="0" cellpadding="20">
          <tr>
            <td>
              <br>
              <p align="right">
                <font size="2">
		  
                 Last updated on Sep 16, 2021. Thanks to <a href="https://people.eecs.berkeley.edu/~barron/">Jon Barron</a> for this minimalist website template.
                </font>
              </p>
            </td>
          </tr>
        </table>        
        </td>
      </tr>
    </table>
    <script xml:space="preserve" language="JavaScript">
      hideallbibs();
    </script>
    <script xml:space="preserve" language="JavaScript">
      hideblock('3dpaper_abs');
    </script>
    <script xml:space="preserve" language="JavaScript">
      hideblock('rwfm_abs');
    </script>
    <script xml:space="preserve" language="JavaScript">
      hideblock('ads_abs');
    </script>
    <script>
  (function(i,s,o,g,r,a,m){i['GoogleAnalyticsObject']=r;i[r]=i[r]||function(){
  (i[r].q=i[r].q||[]).push(arguments)},i[r].l=1*new Date();a=s.createElement(o),
  m=s.getElementsByTagName(o)[0];a.async=1;a.src=g;m.parentNode.insertBefore(a,m)
  })(window,document,'script','https://www.google-analytics.com/analytics.js','ga');

  ga('create', 'UA-102204172-1', 'auto');
  ga('send', 'pageview');

</script>
    <script>
  

</script>
  </body>
</html>
